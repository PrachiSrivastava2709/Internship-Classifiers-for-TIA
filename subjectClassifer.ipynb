{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d467c-7f20-4899-a648-b35ad6a781ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e078041-8b3c-4141-9b5a-28ae5a5486c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd88189-38ec-4c75-aabb-a9f94bcf3052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "data = []\n",
    "with open('Dataset/Data.csv') as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for row in spamreader:\n",
    "        data.append(row[0].split('|++|'))\n",
    "data = pd.DataFrame(data, columns=['id', 'id', 'subjectName', 'topicName', 'chapterName', 'levelDescription', 'Question', 'Answer']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03696f9-eaf9-4293-992c-288b4b780b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Drop null values\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d601bb3-299d-463b-94e8-b45102eb6967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Use only Subject and Question columns\n",
    "data = data.iloc[:, [False, False, True, False, False, False, True, False]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a711d9-e440-4031-9f92-2333822776c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Shuffle data\n",
    "data = data.sample(n=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180db64-86ed-4964-bec0-0ea0c05cd70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c78c33-985d-4d1a-bb8f-55a42021b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------Classifier--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1664332-4c59-4851-b679-9f4e98c1cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087aaff-e129-45e6-aadb-3be158cf5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spacy English language model\n",
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b902f092-eb67-4fc6-94fd-5478ec9719d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories\n",
    "categories = data['subjectName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cebc7b-7ff8-478c-ae6d-e61d835e12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the text categorizer pipe for the Spacy model\n",
    "textcat = nlp.add_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e3a287-a10d-4b9b-a99d-d276d2db7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the categories to the text categorizer\n",
    "for category in categories:\n",
    "    textcat.add_label(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b58baa-aea1-45ff-a7fd-76cbb697a966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train-test Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdb209-7fd4-4e6e-8dc4-9c732a5cd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training data to binary format\n",
    "doc_bin = DocBin()\n",
    "for i, row in data.iterrows():\n",
    "    text = row['Question']\n",
    "    labels = {category: False for category in categories}\n",
    "    labels[row['subjectName']] = True\n",
    "    example = Example.from_dict(nlp.make_doc(text), {\"cats\": labels})\n",
    "    doc_bin.add(example.reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc7240-1c57-47bd-b003-ca60fe599bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the text categorizer\n",
    "from spacy.util import minibatch, compounding\n",
    "train_data = list(doc_bin.get_docs(nlp.vocab))\n",
    "train_examples = []\n",
    "for doc in train_data:\n",
    "    labels = doc.cats\n",
    "    example = Example.from_dict(doc, {\"cats\": labels})\n",
    "    train_examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4342b4b-9754-4882-a047-7b586353eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "batch_size = 4\n",
    "learn_rate = 0.001\n",
    "dropout = 0.2\n",
    "optimizer = nlp.initialize(lambda: train_examples)\n",
    "for i in range(n_iter):\n",
    "    losses = {}\n",
    "    batches = minibatch(train_examples, size =compounding(batch_size, 32, 1.001))\n",
    "    for batch in batches:\n",
    "        nlp.update(batch, sgd=optimizer, drop=dropout, losses=losses)\n",
    "    print(\"Iteration:\", i, \"Loss:\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134497b-8d54-41e6-bad6-e1bf579176bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the text-categorizer\n",
    "test_data, test_labels = [], []\n",
    "for i, row in test.iterrows():\n",
    "    test_data.append(row[\"Question\"])\n",
    "    test_labels.append(row['subjectName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7238282-c0d2-452a-a175-36e1715ddd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for text in test_data:\n",
    "    doc = nlp(text)\n",
    "    predicted.append(max(doc.cats, key=doc.cats.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907ac92-265c-45e3-acd4-08cf1b1b0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation: Accuracy\n",
    "score = 0\n",
    "for actual, predict in zip(test_labels, predicted):\n",
    "    #print(actual, predict)\n",
    "    if actual == predict:\n",
    "        score += 1\n",
    "print(score / len(test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
